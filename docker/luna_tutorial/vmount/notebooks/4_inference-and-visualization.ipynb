{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference and Visualization Tutorial\n",
    "\n",
    "Welcome to the inference and visualization notebook! At this point, you should have a trained model and tiles to run inference. In this notebook we will run inference on a slide and visualize the results. Here are the steps we will review:\n",
    "\n",
    "- Run inference with a trained model.\n",
    "- Visualize the inference results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run inference with a trained model\n",
    "\n",
    "Often tissue-based analysis on whole slide images benefit from annotations provided by expert pathologists. However, having pathologists annotate 1000s of slides is very time consuming and expensive. To overcome this bottleneck, it is common to have pathologist annotate a subset of the slides, and use that dataset to train a model. This model is then used to label the rest of the dataset.\n",
    "\n",
    "In the model training notebook, we trained a ResNet-18 model on a subset of our slides with the annotated regions and labels. We will now use this trained model and the prepared tiles from the test slide to run the inference step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "HOME = os.environ['HOME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env DATASET_URL=file:///$HOME/vmount/PRO-12-123/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!infer_tiles --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`infer_tiles` CLI takes in details on your trained model, and loads the tiles data for inference.\n",
    "\n",
    "First we need to copy the model checkpoint into the `classifier` directory where we have a `hubconf.py` file that defines the model settings. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp ../PRO-12-123/tissue_classifier_results/checkpoint_1.pt ~/vmount/classifier/model.checkpoint "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to generate tiles for the slides we want to compute predictions on. Previously, we only generated tiles for portions of the whole slide that contained annotations. Now, we want to tile the entire slide and only remove tiles that have background/glass and keep all of tiles containing tissue. \n",
    "\n",
    "Just like before, the pipeline is to first `generate_tiles` for a particular slide, then to run `detect_tissue` to remove glass using an otsu threshold, and then to `save_tiles`, which we can use for inference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!generate_tiles \\\n",
    "file:~/vmount/PRO-12-123/data/toy_data_set/01OV002-bd8cdc70-3d46-40ae-99c4-90ef77.svs \\\n",
    "--tile_size 128 --requested_magnification 20 \\\n",
    "-o ~/vmount/PRO-12-123/tiling/inference/tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!detect_tissue \\\n",
    "~/vmount/PRO-12-123/data/toy_data_set/01OV002-bd8cdc70-3d46-40ae-99c4-90ef77.svs \\\n",
    "~/vmount/PRO-12-123/tiling/inference/tiles \\\n",
    "--requested_magnification 2 \\\n",
    "--filter_query \"otsu_score > 0.1\" \\\n",
    "-o ~/vmount/PRO-12-123/tiling/inference/detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!save_tiles \\\n",
    "~/vmount/PRO-12-123/data/toy_data_set/01OV002-bd8cdc70-3d46-40ae-99c4-90ef77.svs \\\n",
    "~/vmount/PRO-12-123/tiling/inference/detect \\\n",
    "--num_cores 16 --batch_size 200 --dataset_id PRO_TILES_INFERENCE \\\n",
    "-o ~/vmount/PRO-12-123/tiling/inference/saved_tiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a set of saved tiles, we can run inference by specifying the dataset of saved tiles and some parameters about our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!infer_tiles ~/vmount/PRO-12-123/datasets/PRO_TILES_INFERENCE/ \\\n",
    "--output_dir ../PRO-12-123/sample_tiles_inference \\\n",
    "--hub_repo_or_dir ~/vmount/classifier \\\n",
    "--model_name 'tissue_classifier' \\\n",
    "--num_cores 4 \\\n",
    "--batch_size 16 \\\n",
    "-kw \"{'network':'torchvision.models.resnet18', 'num_labels': 3}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the inference is saved in a paquet file. Let's take a look at the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lhtr ../PRO_12-123/sample_tiles_inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = pd.read_parquet(\"../PRO_12-123/sample_tiles_inference/tile_scores_and_labels_pytorch_inference.parquet\")\n",
    "\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the inference results \n",
    "\n",
    "Now we will visualize the inference results. **visualize_tiles_png** CLI creates heatmaps based on the scores, and saves the thumbnail images in png format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!visualize_tiles_png --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to evaluate your model results in detail, it is desirable to review the results and images in high-magnification.\n",
    "We use [Digital Slide Archive (DSA)](https://digitalslidearchive.github.io/digital_slide_archive/) viewer to examine the high resolution image and results. DSA is a web-based platform and this enables us to easily share the images and model results with other researchers via a link.\n",
    "\n",
    "A set of CLIs are available to help you convert your pathologist or model-generated annotations and push them to DSA. Please refer to the `dsa-tools.ipynb` notebook for more details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!visualize_tiles_png \\\n",
    "~/vmount/PRO-12-123/data/toy_data_set/01OV002-bd8cdc70-3d46-40ae-99c4-90ef77.svs \\\n",
    "../PRO-12-123/sample_tiles_inference/tile_scores_and_labels_pytorch_inference.parquet \\\n",
    "--output_dir ../PRO-12-123/sample_tiles_viz \\\n",
    "--plot_labels 0 \\\n",
    "--requested_magnification 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image('../PRO-12-123/sample_tiles_viz/tile_scores_and_labels_visualization_0.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations on completing the inference and visualization notebook! To view the end-to-end pipeline of the tiling workflow, please checkout the end-to-end notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

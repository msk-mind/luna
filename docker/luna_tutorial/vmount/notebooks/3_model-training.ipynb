{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea3f7a22",
   "metadata": {},
   "source": [
    "# Model Training Tutorial\n",
    "\n",
    "Welcome to the model training tutorial! In this tutorial, we will train a neural network to classify tiles from our toy data set and visualize its efficacy. Our model is essentially a wrapper around PyTorch's ResNet 18 deep residual network; the LUNA team modified it to suit their work with tiling the slides. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d959b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup home directory\n",
    "import os\n",
    "HOME = os.environ['HOME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d99f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "env DATASET_URL=file:///$HOME/vmount/PRO_12-123/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e17f93",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "\n",
    "The model will be used to classify tiles into the different tissue types we've annotated (tumor, stroma and fat). These tissue classifier models can be trained using the `train_tissue_classifier` CLI tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8b6be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!train_tissue_classifier --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40275193",
   "metadata": {},
   "source": [
    "This CLI tool has a many command line arguments. The main input is the labled tile dataset, which is the data used to train and valdiate the model. For validation, the tiles are stratified by patient id and by slide id, and the split is contoleled by the `num_splits` parameter. The `label_set` parameter is used to map the tissue types to numerical quantities. These models can use none, one, or many GPUs/CPUs using Ray. The arguments used to modify the resources are `num_gpus, num_cpus, num_workers, num_cpus_per_worker, num_gpus_per_worker`. If you want to experiment with different hyperparameters, you can supply a list of values to certian arguments, such as `learning_rate` or `batch_size` and Ray will perform a hyperparameter search or sweep accordingly. \n",
    "\n",
    "In the following example, we're going to train a ResNet18 model (though any model available from [PyTorch](https://pytorch.org/vision/stable/models.html) can be used) for two epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef8144c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "train_tissue_classifier ~/vmount/PRO_12-123/datasets/PRO_TILES_LABLED/ \\\n",
    "--label_set \"{'tumor':0, 'stroma':1, 'fat':2}\" \\\n",
    "--label_col regional_label --stratify_col slide_id \\\n",
    "--num_epochs 2 --network 'torchvision.models.resnet18' \\\n",
    "--num_splits 2 \\\n",
    "--batch_size 4 \\\n",
    "-lr 1e-4  \\\n",
    "-cw 4 -gw 0 -nw 1 -ng 0 -nc 4 -ns 1 \\\n",
    "--output_dir ../PRO_12-123/tissue_classifier_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b59013",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "Now that we have a trained model, we can inspect the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002585c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lat ../PRO_12-123/tissue_classifier_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d16db1f",
   "metadata": {},
   "source": [
    "For every time the model is trained, Ray will put together a set of output directories to manage your runs. You can inspect the results using Ray's ExperimentAnalysis dataframe by loading a particular output directory. This dataframe will store various performance metrics as well as the hyperparameters used to configure the model among other output metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75de5070",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.tune import ExperimentAnalysis\n",
    "RAY_OUTPUT = \"tune_function_2022-05-17_00-11-34\" # change this to the output folder you want to insepct\n",
    "output_dir = \"../PRO_12-123/tissue_classifier_results\"\n",
    "\n",
    "ray_output_dir = os.path.join(output_dir, RAY_OUTPUT)\n",
    "analysis = ExperimentAnalysis(ray_output_dir)\n",
    "display(analysis.results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256b85a0",
   "metadata": {},
   "source": [
    "We can use the output to put together a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5366d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "label_dict = {'tumor':0, 'stroma':1, 'fat':2}\n",
    "labels = list(label_dict.keys())\n",
    "cm = analysis.results_df['val_ConfusionMatrix'].iloc[0]\n",
    "\n",
    "# normalize \n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "df_cm = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "df_cm\n",
    "sns.heatmap(df_cm, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93bd09c",
   "metadata": {},
   "source": [
    "The ray output directory also contains a tensorboard file (`events.out.tf.events.*`) in the `'tune_function_*'` subdirectory that can be used to further evaluate the performance of the model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1584d736",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree $output_dir\n",
    "# %load_ext tensorboard\n",
    "# ! tensorboard --logdir os.path.join(ray_output_dir,'tune_function_ff99e_00000_0_batch_size=4,learning_rate=0.0001,num_epochs=2_2022-05-10_13-49-23') --bind_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c999c1",
   "metadata": {},
   "source": [
    "This output directory directory also contains our model checkpoints `checkpoint_*.pt` that we'll need for inference. Now, with our trained model and model checkpoints, we can move on the next notebook!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

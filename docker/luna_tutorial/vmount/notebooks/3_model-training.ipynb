{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training Tutorial\n",
    "\n",
    "Welcome to the model training tutorial! In this tutorial, we will train a neural network to classify tiles from our toy data set and visualize its efficacy. Our model is essentially a wrapper around PyTorch's ResNet 18 deep residual network; the LUNA team modified it to suit their work with tiling the slides. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup home directory\n",
    "import os\n",
    "HOME = os.environ['HOME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DATASET_URL=file:////home/pashaa/vmount/PRO-12-123/\n"
     ]
    }
   ],
   "source": [
    "env DATASET_URL=file:///$HOME/vmount/PRO-12-123/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "\n",
    "The model will be used to classify tiles into the different tissue types we've annotated (tumor, stroma and fat). These tissue classifier models can be trained using the `train_tissue_classifier` CLI tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-22 12:24:54,749 - INFO - root - Initalized logger, log file at: luna.log\r\n",
      "Usage: train_tissue_classifier [OPTIONS] TILE_DATASET_FPATH\r\n",
      "\r\n",
      "  Train a tissue classifier model for all tiles in a slide\r\n",
      "\r\n",
      "  Inputs:\r\n",
      "      tile_dataset_fpath: path to tile dataset parquet table\r\n",
      "  \b\r\n",
      "  Outputs:\r\n",
      "      ray ExperimentAnalysis dataframe and metadata saved to the output\r\n",
      "  \b\r\n",
      "  Example:\r\n",
      "      train_tissue_classifier /tables/slides/slide_table\r\n",
      "          -ne 5\r\n",
      "          -nt torchvision.models.resnet18\r\n",
      "          -nw 1\r\n",
      "          -o results/train_tile_classifier_results\r\n",
      "\r\n",
      "Options:\r\n",
      "  -o, --output_dir TEXT           Path to output directory to save results and\r\n",
      "                                  logs from Ray\r\n",
      "  -ls, --label_set TEXT           Dictionary/json where keys coorespoond to\r\n",
      "                                  tissue types and values coorespond to\r\n",
      "                                  numerical values\r\n",
      "  -lc, --label_col TEXT           Column name in the input dataframe\r\n",
      "                                  cooresponding to the tissue type (eg.\r\n",
      "                                  regional_label)\r\n",
      "  -sc, --stratify_col TEXT        Column name in the input dataframe used to\r\n",
      "                                  stratify the training/validation datasets\r\n",
      "                                  (eg. id_slide_container or patient_id)\r\n",
      "  -nk, --num_splits TEXT          The number of folds used for cross\r\n",
      "                                  validation\r\n",
      "  -ne, --num_epochs TEXT          Number of epochs to train the model for. Can\r\n",
      "                                  be either a fixed integer or a RayTune grid\r\n",
      "                                  search\r\n",
      "  -bx, --batch_size TEXT          Batch size used train the model. Can be\r\n",
      "                                  either a fixed integer or a RayTune grid\r\n",
      "                                  search\r\n",
      "  -lr, --learning_rate TEXT       Learning rate used for the ADAM optimizer.\r\n",
      "                                  Can be either a float or a RayTune\r\n",
      "                                  distribution\r\n",
      "  -nt, --network TEXT             Neural network architecture. Can be either a\r\n",
      "                                  nn.Module or a RayTune grid search\r\n",
      "  -ug, --use_gpu TEXT             Whether or not use use GPUs for model\r\n",
      "                                  training\r\n",
      "  -cw, --num_cpus_per_worker TEXT\r\n",
      "                                  Number of CPUs transparent to each worker\r\n",
      "  -gw, --num_gpus_per_worker TEXT\r\n",
      "                                  Number of GPUs transparent to each worker.\r\n",
      "                                  Can't be more than num_gpus\r\n",
      "  -ng, --num_gpus TEXT            Number of GPUs in total transparent to Ray\r\n",
      "  -nc, --num_cpus TEXT            Number of CPUs in total transparent to Ray\r\n",
      "  -nw, --num_workers TEXT         Total number of workers. Cooresponds to\r\n",
      "                                  number of models to train concurrently.\r\n",
      "  -ns, --num_samples TEXT         number of trials to run\r\n",
      "  -m, --method_param_path TEXT    path to a metadata json/yaml file with\r\n",
      "                                  method parameters to reproduce results\r\n",
      "  --help                          Show this message and exit.\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!train_tissue_classifier --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This CLI tool has a many command line arguments. The main input is the labled tile dataset, which is the data used to train and valdiate the model. For validation, the tiles are stratified by patient id and by slide id, and the split is contoleled by the `num_splits` parameter. The `label_set` parameter is used to map the tissue types to numerical quantities. These models can use none, one, or many GPUs/CPUs using Ray. The arguments used to modify the resources are `num_gpus, num_cpus, num_workers, num_cpus_per_worker, num_gpus_per_worker`. If you want to experiment with different hyperparameters, you can supply a list of values to certian arguments, such as `learning_rate` or `batch_size` and Ray will perform a hyperparameter search or sweep accordingly. \n",
    "\n",
    "In the following example, we're going to train a ResNet18 model (though any model available from [PyTorch](https://pytorch.org/vision/stable/models.html) can be used) for two epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-22 12:25:00,318 - INFO - root - Initalized logger, log file at: luna.log\n",
      "2022-08-22 12:25:00,320 - INFO - luna.common.utils - Started CLI Runner wtih <function train_model at 0x7f50016c1430>\n",
      "2022-08-22 12:25:00,321 - INFO - luna.common.utils - Validating params...\n",
      "2022-08-22 12:25:00,323 - INFO - luna.common.utils -  -> Set tile_dataset_fpath (<class 'str'>) = /home/pashaa/vmount/PRO-12-123/datasets/PRO_TILES_LABELED/\n",
      "2022-08-22 12:25:00,324 - INFO - luna.common.utils -  -> Set output_dir (<class 'str'>) = ../PRO-12-123/tissue_classifier_results\n",
      "2022-08-22 12:25:00,326 - INFO - luna.common.utils -  -> Set label_set (<class 'dict'>) = {'tumor': 0, 'stroma': 1, 'fat': 2}\n",
      "2022-08-22 12:25:00,328 - INFO - luna.common.utils -  -> Set label_col (<class 'str'>) = regional_label\n",
      "2022-08-22 12:25:00,330 - INFO - luna.common.utils -  -> Set stratify_col (<class 'str'>) = slide_id\n",
      "2022-08-22 12:25:00,332 - INFO - luna.common.utils -  -> Set num_splits (<class 'int'>) = 2\n",
      "2022-08-22 12:25:00,333 - INFO - luna.common.utils -  -> Set num_epochs (typing.List[int]) = [2]\n",
      "2022-08-22 12:25:00,336 - INFO - luna.common.utils -  -> Set batch_size (typing.List[int]) = [4]\n",
      "2022-08-22 12:25:00,337 - INFO - luna.common.utils -  -> Set learning_rate (typing.List[float]) = [0.0001]\n",
      "2022-08-22 12:25:00,339 - INFO - luna.common.utils -  -> Set network (<class 'str'>) = torchvision.models.resnet18\n",
      "2022-08-22 12:25:00,341 - INFO - luna.common.utils -  -> Set num_cpus_per_worker (<class 'int'>) = 4\n",
      "2022-08-22 12:25:00,343 - INFO - luna.common.utils -  -> Set num_gpus_per_worker (<class 'int'>) = 0\n",
      "2022-08-22 12:25:00,345 - INFO - luna.common.utils -  -> Set num_gpus (<class 'int'>) = 0\n",
      "2022-08-22 12:25:00,347 - INFO - luna.common.utils -  -> Set num_cpus (<class 'int'>) = 4\n",
      "2022-08-22 12:25:00,349 - INFO - luna.common.utils -  -> Set num_workers (<class 'int'>) = 1\n",
      "2022-08-22 12:25:00,351 - INFO - luna.common.utils -  -> Set num_samples (<class 'int'>) = 1\n",
      "2022-08-22 12:25:00,354 - INFO - luna.common.utils - Expanding inputs...\n",
      "2022-08-22 12:25:00,356 - INFO - luna.common.utils - Full segment key set: {}\n",
      "2022-08-22 12:25:00,360 - INFO - luna.common.utils - ------------------------------------------------------------\n",
      "2022-08-22 12:25:00,360 - INFO - luna.common.utils -  Starting transform::train_model \n",
      "2022-08-22 12:25:00,360 - INFO - luna.common.utils - ------------------------------------------------------------\n",
      "2022-08-22 12:25:00,363 - INFO - train_tissue_classifier - Training a tissue classifier with: network=torchvision.models.resnet18, batch_size=[4], learning_rate=[0.0001]\n",
      "2022-08-22 12:25:00,364 - INFO - train_tissue_classifier - Initilizing Ray Cluster, with: num_gpus=0, num_workers=1\n",
      "2022-08-22 12:25:02,996\tWARNING services.py:2002 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67108864 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=3.97gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "2022-08-22 12:25:05,102 - INFO - train_tissue_classifier - View Ray Dashboard to see worker logs:\n",
      "2022-08-22 12:25:05,104 - INFO - train_tissue_classifier - training model\n",
      "2022-08-22 12:25:05,106 - INFO - train_tissue_classifier - Instantiating Ray Trainer with: num_cpus_per_worker=4, num_gpus_per_worker=0\n",
      "2022-08-22 12:25:05,110\tINFO trainer.py:243 -- Trainer logs will be logged in: /home/pashaa/PRO-12-123/tissue_classifier_results\n",
      "2022-08-22 12:25:05,149 - INFO - train_tissue_classifier - Trainer logs will be logged in: ../PRO-12-123/tissue_classifier_results\n",
      "2022-08-22 12:25:07,510\tERROR syncer.py:147 -- Log sync requires rsync to be installed.\n",
      "2022-08-22 12:25:13,266 - INFO - train_tissue_classifier - == Status ==\n",
      "2022-08-22 12:25:13,266 - INFO - train_tissue_classifier - Current time: 2022-08-22 12:25:13 (running for 00:00:05.93)\n",
      "2022-08-22 12:25:13,266 - INFO - train_tissue_classifier - Memory usage on this node: 5.0/13.7 GiB\n",
      "2022-08-22 12:25:13,266 - INFO - train_tissue_classifier - Using FIFO scheduling algorithm.\n",
      "2022-08-22 12:25:13,266 - INFO - train_tissue_classifier - Resources requested: 2.0/4 CPUs, 0/0 GPUs, 0.0/7.21 GiB heap, 0.0/3.61 GiB objects\n",
      "2022-08-22 12:25:13,266 - INFO - train_tissue_classifier - Result logdir: /home/pashaa/vmount/PRO-12-123/tissue_classifier_results/tune_function_2022-08-22_12-25-07\n",
      "2022-08-22 12:25:13,266 - INFO - train_tissue_classifier - Number of trials: 1/1 (1 RUNNING)\n",
      "2022-08-22 12:25:13,266 - INFO - train_tissue_classifier - +---------------------------+----------+-----------------+--------------+-----------------+--------------+\n",
      "2022-08-22 12:25:13,266 - INFO - train_tissue_classifier - | Trial name                | status   | loc             |   batch_size |   learning_rate |   num_epochs |\n",
      "2022-08-22 12:25:13,266 - INFO - train_tissue_classifier - |---------------------------+----------+-----------------+--------------+-----------------+--------------|\n",
      "2022-08-22 12:25:13,266 - INFO - train_tissue_classifier - | tune_function_751a9_00000 | RUNNING  | 172.18.0.6:2140 |            4 |          0.0001 |            2 |\n",
      "2022-08-22 12:25:13,266 - INFO - train_tissue_classifier - +---------------------------+----------+-----------------+--------------+-----------------+--------------+\n",
      "2022-08-22 12:25:13,266 - INFO - train_tissue_classifier -\n",
      "\u001b[2m\u001b[36m(pid=2140)\u001b[0m 2022-08-22 12:25:13,243 - INFO - root - Initalized logger, log file at: luna.log\n",
      "\u001b[2m\u001b[36m(TrainTrainable pid=2140)\u001b[0m 2022-08-22 12:25:13,369\tINFO trainer.py:243 -- Trainer logs will be logged in: /home/pashaa/ray_results/train_2022-08-22_12-25-13\n",
      "\u001b[2m\u001b[36m(TrainTrainable pid=2140)\u001b[0m 2022-08-22 12:25:19,979\tINFO trainer.py:249 -- Run results will be logged in: /home/pashaa/ray_results/train_2022-08-22_12-25-13/run_001\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2213)\u001b[0m 2022-08-22 12:25:19,973\tINFO torch.py:346 -- Setting up process group for: env:// [rank=0, world_size=1]\n",
      "\u001b[2m\u001b[36m(BackendExecutor pid=2180)\u001b[0m 2022-08-22 12:25:22,719 - INFO - root - Initalized logger, log file at: luna.log\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2213)\u001b[0m 2022-08-22 12:25:25,062 - INFO - root - Initalized logger, log file at: luna.log\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2213)\u001b[0m 2022-08-22 12:25:25,066 - INFO - train_tissue_classifier - Configuring model training driver function...\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2213)\u001b[0m 2022-08-22 12:25:25,254\tINFO torch.py:98 -- Moving model to device: cpu\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2213)\u001b[0m 2022-08-22 12:25:25,261 - INFO - train_tissue_classifier - Starting training procedure\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2213)\u001b[0m 2022-08-22 12:26:58,675 - INFO - train_tissue_classifier - Completed model training\n",
      "2022-08-22 12:26:59,012 - INFO - train_tissue_classifier - == Status ==\n",
      "2022-08-22 12:26:59,012 - INFO - train_tissue_classifier - Current time: 2022-08-22 12:26:59 (running for 00:01:51.68)\n",
      "2022-08-22 12:26:59,012 - INFO - train_tissue_classifier - Memory usage on this node: 5.5/13.7 GiB\n",
      "2022-08-22 12:26:59,012 - INFO - train_tissue_classifier - Using FIFO scheduling algorithm.\n",
      "2022-08-22 12:26:59,012 - INFO - train_tissue_classifier - Resources requested: 0/4 CPUs, 0/0 GPUs, 0.0/7.21 GiB heap, 0.0/3.61 GiB objects\n",
      "2022-08-22 12:26:59,012 - INFO - train_tissue_classifier - Current best trial: 751a9_00000 with val_Accuracy=0.8022988438606262 and parameters={'learning_rate': 0.0001, 'batch_size': 4, 'num_epochs': 2, 'num_cpus_per_worker': 4, 'tile_dataset_fpath': '/home/pashaa/vmount/PRO-12-123/datasets/PRO_TILES_LABELED/', 'label_set': {'tumor': 0, 'stroma': 1, 'fat': 2}, 'label_col': 'regional_label', 'stratify_col': 'slide_id', 'network': <function resnet18 at 0x7f502b009280>, 'num_splits': 2, 'checkpoint_dir': '../PRO-12-123/tissue_classifier_results'}\n",
      "2022-08-22 12:26:59,012 - INFO - train_tissue_classifier - Result logdir: /home/pashaa/vmount/PRO-12-123/tissue_classifier_results/tune_function_2022-08-22_12-25-07\n",
      "2022-08-22 12:26:59,012 - INFO - train_tissue_classifier - Number of trials: 1/1 (1 TERMINATED)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-22 12:26:59,012 - INFO - train_tissue_classifier - +---------------------------+------------+-----------------+--------------+-----------------+--------------+--------+------------------+--------------+------------+--------------+\n",
      "2022-08-22 12:26:59,012 - INFO - train_tissue_classifier - | Trial name                | status     | loc             |   batch_size |   learning_rate |   num_epochs |   iter |   total time (s) |   train_loss |   val_loss |   _timestamp |\n",
      "2022-08-22 12:26:59,012 - INFO - train_tissue_classifier - |---------------------------+------------+-----------------+--------------+-----------------+--------------+--------+------------------+--------------+------------+--------------|\n",
      "2022-08-22 12:26:59,012 - INFO - train_tissue_classifier - | tune_function_751a9_00000 | TERMINATED | 172.18.0.6:2140 |            4 |          0.0001 |            2 |      2 |          105.148 |     0.429982 |   0.537632 |   1661171218 |\n",
      "2022-08-22 12:26:59,012 - INFO - train_tissue_classifier - +---------------------------+------------+-----------------+--------------+-----------------+--------------+--------+------------------+--------------+------------+--------------+\n",
      "2022-08-22 12:26:59,012 - INFO - train_tissue_classifier -\n",
      "2022-08-22 12:26:59,124\tINFO tune.py:747 -- Total run time: 111.86 seconds (111.66 seconds for the tuning loop).\n",
      "2022-08-22 12:26:59,139 - INFO - train_tissue_classifier - Finished training\n",
      "/home/pashaa/.local/lib/python3.9/site-packages/ray/tune/analysis/experiment_analysis.py:303: UserWarning: Dataframes will use '/' instead of '.' to delimit nested result keys in future versions of Ray. For forward compatibility, set the environment variable TUNE_RESULT_DELIM='/'\n",
      "  warnings.warn(\n",
      "2022-08-22 12:26:59,190 - INFO - train_tissue_classifier -             train_Accuracy  ... config.label_set.fat\n",
      "2022-08-22 12:26:59,190 - INFO - train_tissue_classifier - trial_id                    ...                     \n",
      "2022-08-22 12:26:59,190 - INFO - train_tissue_classifier - 751a9_00000      0.7509091  ...                    2\n",
      "2022-08-22 12:26:59,190 - INFO - train_tissue_classifier - \n",
      "2022-08-22 12:26:59,190 - INFO - train_tissue_classifier - [1 rows x 44 columns]\n",
      "2022-08-22 12:26:59,202 - INFO - train_tissue_classifier - Output: ../PRO-12-123/tissue_classifier_results\n",
      "2022-08-22 12:27:01,641 - INFO - luna.common.utils - Code block 'transform::train_model' took: 121.36113332900004s\n",
      "2022-08-22 12:27:01,644 - INFO - luna.common.utils - ------------------------------------------------------------\n",
      "2022-08-22 12:27:01,644 - INFO - luna.common.utils -  Done with transform, running post-transform functions... \n",
      "2022-08-22 12:27:01,644 - INFO - luna.common.utils - ------------------------------------------------------------\n",
      "2022-08-22 12:27:01,668 - INFO - luna.common.utils - Done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for tune_function_751a9_00000:\n",
      "  _time_this_iter_s: 45.18546223640442\n",
      "  _timestamp: 1661171170\n",
      "  _training_iteration: 1\n",
      "  date: 2022-08-22_12-26-10\n",
      "  done: false\n",
      "  experiment_id: 0b1712a81fa24fe8b4b731e2fd28d3e7\n",
      "  hostname: 0f3514bd5ee0\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 172.18.0.6\n",
      "  pid: 2140\n",
      "  time_since_restore: 56.98853397369385\n",
      "  time_this_iter_s: 56.98853397369385\n",
      "  time_total_s: 56.98853397369385\n",
      "  timestamp: 1661171170\n",
      "  timesteps_since_restore: 0\n",
      "  train_Accuracy: 0.6836363673210144\n",
      "  train_F1Score: 0.6836363673210144\n",
      "  train_Precision: 0.6836363673210144\n",
      "  train_Recall: 0.6836363673210144\n",
      "  train_loss: 0.7305730086737785\n",
      "  training_iteration: 1\n",
      "  trial_id: 751a9_00000\n",
      "  val_Accuracy: 0.8045976758003235\n",
      "  val_ConfusionMatrix:\n",
      "  - - 527\n",
      "    - 1\n",
      "    - 3\n",
      "  - - 55\n",
      "    - 3\n",
      "    - 73\n",
      "  - - 37\n",
      "    - 1\n",
      "    - 170\n",
      "  val_F1Score: 0.8045976758003235\n",
      "  val_Precision: 0.8045976758003235\n",
      "  val_Recall: 0.8045976758003235\n",
      "  val_loss: 0.6162708169746495\n",
      "  warmup_time: 0.00412297248840332\n",
      "  \n",
      "Result for tune_function_751a9_00000:\n",
      "  _time_this_iter_s: 48.1574592590332\n",
      "  _timestamp: 1661171218\n",
      "  _training_iteration: 2\n",
      "  date: 2022-08-22_12-26-58\n",
      "  done: false\n",
      "  experiment_id: 0b1712a81fa24fe8b4b731e2fd28d3e7\n",
      "  hostname: 0f3514bd5ee0\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 172.18.0.6\n",
      "  pid: 2140\n",
      "  time_since_restore: 105.14810085296631\n",
      "  time_this_iter_s: 48.15956687927246\n",
      "  time_total_s: 105.14810085296631\n",
      "  timestamp: 1661171218\n",
      "  timesteps_since_restore: 0\n",
      "  train_Accuracy: 0.7509090900421143\n",
      "  train_F1Score: 0.7509090900421143\n",
      "  train_Precision: 0.7509090900421143\n",
      "  train_Recall: 0.7509090900421143\n",
      "  train_loss: 0.42998192750889325\n",
      "  training_iteration: 2\n",
      "  trial_id: 751a9_00000\n",
      "  val_Accuracy: 0.8022988438606262\n",
      "  val_ConfusionMatrix:\n",
      "  - - 1017\n",
      "    - 42\n",
      "    - 3\n",
      "  - - 100\n",
      "    - 77\n",
      "    - 85\n",
      "  - - 64\n",
      "    - 50\n",
      "    - 302\n",
      "  val_F1Score: 0.8022988438606262\n",
      "  val_Precision: 0.8022988438606262\n",
      "  val_Recall: 0.8022988438606262\n",
      "  val_loss: 0.5376319679252188\n",
      "  warmup_time: 0.00412297248840332\n",
      "  \n",
      "Result for tune_function_751a9_00000:\n",
      "  _time_this_iter_s: 48.1574592590332\n",
      "  _timestamp: 1661171218\n",
      "  _training_iteration: 2\n",
      "  date: 2022-08-22_12-26-58\n",
      "  done: true\n",
      "  experiment_id: 0b1712a81fa24fe8b4b731e2fd28d3e7\n",
      "  experiment_tag: 0_batch_size=4,learning_rate=0.0001,num_epochs=2\n",
      "  hostname: 0f3514bd5ee0\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 172.18.0.6\n",
      "  pid: 2140\n",
      "  time_since_restore: 105.14810085296631\n",
      "  time_this_iter_s: 48.15956687927246\n",
      "  time_total_s: 105.14810085296631\n",
      "  timestamp: 1661171218\n",
      "  timesteps_since_restore: 0\n",
      "  train_Accuracy: 0.7509090900421143\n",
      "  train_F1Score: 0.7509090900421143\n",
      "  train_Precision: 0.7509090900421143\n",
      "  train_Recall: 0.7509090900421143\n",
      "  train_loss: 0.42998192750889325\n",
      "  training_iteration: 2\n",
      "  trial_id: 751a9_00000\n",
      "  val_Accuracy: 0.8022988438606262\n",
      "  val_ConfusionMatrix:\n",
      "  - - 1017\n",
      "    - 42\n",
      "    - 3\n",
      "  - - 100\n",
      "    - 77\n",
      "    - 85\n",
      "  - - 64\n",
      "    - 50\n",
      "    - 302\n",
      "  val_F1Score: 0.8022988438606262\n",
      "  val_Precision: 0.8022988438606262\n",
      "  val_Recall: 0.8022988438606262\n",
      "  val_loss: 0.5376319679252188\n",
      "  warmup_time: 0.00412297248840332\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "train_tissue_classifier ~/vmount/PRO-12-123/datasets/PRO_TILES_LABELED/ \\\n",
    "--label_set \"{'tumor':0, 'stroma':1, 'fat':2}\" \\\n",
    "--label_col regional_label --stratify_col slide_id \\\n",
    "--num_epochs 2 --network 'torchvision.models.resnet18' \\\n",
    "--num_splits 2 \\\n",
    "--batch_size 4 \\\n",
    "-lr 1e-4  \\\n",
    "-cw 4 -gw 0 -nw 1 -ng 0 -nc 4 -ns 1 \\\n",
    "--output_dir ../PRO-12-123/tissue_classifier_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "Now that we have a trained model, we can inspect the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 89228\r\n",
      "-rw-r--r-- 1 pashaa pashaa     8892 Aug 22 12:27 metadata.yml\r\n",
      "drwxr-xr-x 5 pashaa pashaa      160 Aug 22 12:26 tune_function_2022-08-22_12-25-07\r\n",
      "-rw-r--r-- 1 pashaa pashaa 44788557 Aug 22 12:26 checkpoint_1.pt\r\n",
      "-rw-r--r-- 1 pashaa pashaa 44788557 Aug 22 12:26 checkpoint_0.pt\r\n",
      "drwxr-xr-x 7 pashaa pashaa      224 Aug 22 12:25 .\r\n",
      "drwxr-xr-x 5 pashaa pashaa      160 Aug 22 12:20 tune_function_2022-08-22_12-19-08\r\n",
      "drwxr-xr-x 8 root   root        256 Aug 22 12:19 ..\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lat ../PRO-12-123/tissue_classifier_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every time the model is trained, Ray will put together a set of output directories to manage your runs. You can inspect the results using Ray's ExperimentAnalysis dataframe by loading a particular output directory. This dataframe will store various performance metrics as well as the hyperparameters used to configure the model among other output metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pashaa/.local/lib/python3.9/site-packages/ray/tune/analysis/experiment_analysis.py:303: UserWarning: Dataframes will use '/' instead of '.' to delimit nested result keys in future versions of Ray. For forward compatibility, set the environment variable TUNE_RESULT_DELIM='/'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_Accuracy</th>\n",
       "      <th>train_Precision</th>\n",
       "      <th>train_Recall</th>\n",
       "      <th>train_F1Score</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_Accuracy</th>\n",
       "      <th>val_Precision</th>\n",
       "      <th>val_Recall</th>\n",
       "      <th>val_F1Score</th>\n",
       "      <th>val_ConfusionMatrix</th>\n",
       "      <th>...</th>\n",
       "      <th>config.num_cpus_per_worker</th>\n",
       "      <th>config.tile_dataset_fpath</th>\n",
       "      <th>config.label_col</th>\n",
       "      <th>config.stratify_col</th>\n",
       "      <th>config.network</th>\n",
       "      <th>config.num_splits</th>\n",
       "      <th>config.checkpoint_dir</th>\n",
       "      <th>config.label_set.tumor</th>\n",
       "      <th>config.label_set.stroma</th>\n",
       "      <th>config.label_set.fat</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trial_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>751a9_00000</th>\n",
       "      <td>0.7509091</td>\n",
       "      <td>0.7509091</td>\n",
       "      <td>0.7509091</td>\n",
       "      <td>0.7509091</td>\n",
       "      <td>0.429982</td>\n",
       "      <td>0.80229884</td>\n",
       "      <td>0.80229884</td>\n",
       "      <td>0.80229884</td>\n",
       "      <td>0.80229884</td>\n",
       "      <td>[[1017, 42, 3], [100, 77, 85], [64, 50, 302]]</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>/home/pashaa/vmount/PRO-12-123/datasets/PRO_TI...</td>\n",
       "      <td>regional_label</td>\n",
       "      <td>slide_id</td>\n",
       "      <td>&lt;function resnet18 at 0x7fd9348d69d0&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>../PRO-12-123/tissue_classifier_results</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            train_Accuracy train_Precision train_Recall train_F1Score  \\\n",
       "trial_id                                                                \n",
       "751a9_00000      0.7509091       0.7509091    0.7509091     0.7509091   \n",
       "\n",
       "             train_loss val_Accuracy val_Precision  val_Recall val_F1Score  \\\n",
       "trial_id                                                                     \n",
       "751a9_00000    0.429982   0.80229884    0.80229884  0.80229884  0.80229884   \n",
       "\n",
       "                                       val_ConfusionMatrix  ...  \\\n",
       "trial_id                                                    ...   \n",
       "751a9_00000  [[1017, 42, 3], [100, 77, 85], [64, 50, 302]]  ...   \n",
       "\n",
       "             config.num_cpus_per_worker  \\\n",
       "trial_id                                  \n",
       "751a9_00000                           4   \n",
       "\n",
       "                                     config.tile_dataset_fpath  \\\n",
       "trial_id                                                         \n",
       "751a9_00000  /home/pashaa/vmount/PRO-12-123/datasets/PRO_TI...   \n",
       "\n",
       "             config.label_col  config.stratify_col  \\\n",
       "trial_id                                             \n",
       "751a9_00000    regional_label             slide_id   \n",
       "\n",
       "                                    config.network  config.num_splits  \\\n",
       "trial_id                                                                \n",
       "751a9_00000  <function resnet18 at 0x7fd9348d69d0>                  2   \n",
       "\n",
       "                               config.checkpoint_dir config.label_set.tumor  \\\n",
       "trial_id                                                                      \n",
       "751a9_00000  ../PRO-12-123/tissue_classifier_results                      0   \n",
       "\n",
       "             config.label_set.stroma config.label_set.fat  \n",
       "trial_id                                                   \n",
       "751a9_00000                        1                    2  \n",
       "\n",
       "[1 rows x 44 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ray.tune import ExperimentAnalysis\n",
    "RAY_OUTPUT = \"tune_function_2022-08-22_12-25-07\" # change this to the output folder you want to insepct\n",
    "output_dir = \"../PRO-12-123/tissue_classifier_results\"\n",
    "\n",
    "ray_output_dir = os.path.join(output_dir, RAY_OUTPUT)\n",
    "analysis = ExperimentAnalysis(ray_output_dir)\n",
    "display(analysis.results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the output to put together a confusion matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "label_dict = {'tumor':0, 'stroma':1, 'fat':2}\n",
    "labels = list(label_dict.keys())\n",
    "cm = analysis.results_df['val_ConfusionMatrix'].iloc[0]\n",
    "\n",
    "# normalize \n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "df_cm = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "df_cm\n",
    "sns.heatmap(df_cm, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This output directory directory also contains our model checkpoints `checkpoint_*.pt` that we'll need for inference. Now, with our trained model and model checkpoints, we can move on the next notebook!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

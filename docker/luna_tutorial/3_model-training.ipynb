{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea3f7a22",
   "metadata": {},
   "source": [
    "# Model Training Tutorial\n",
    "\n",
    "Welcome to the model training tutorial! In this tutorial, we will train a neural network to classify tiles from our toy data set and visualize its efficacy. Our model is essentially a wrapper around PyTorch's ResNet 18 deep residual network; the LUNA team modified it to suit their work with tiling the slides. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d959b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup home directory\n",
    "import os\n",
    "HOME = os.environ['HOME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "27d99f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DATASET_URL=file:////home/kohlia/vmount/PRO_12-123/\n"
     ]
    }
   ],
   "source": [
    "# setup environment \n",
    "env DATASET_URL=file:///$HOME/vmount/PRO_12-123/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e17f93",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "\n",
    "The model will be used to classify tiles into the different tissue types we've annotated (tumor, stroma and fat). These tissue classifier models can be trained using the `train_tissue_classifier` CLI tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "4a8b6be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-10 15:09:07,005 - INFO - root - Initalized logger, log file at: data-processing.log\n",
      "Usage: train_tissue_classifier [OPTIONS] TILE_DATASET_FPATH\n",
      "\n",
      "  Train a tissue classifier model for all tiles in a slide\n",
      "\n",
      "  Inputs:\n",
      "      tile_dataset_fpath: path to tile dataset parquet table\n",
      " \n",
      "  Outputs:\n",
      "      ray ExperimentAnalysis dataframe and metadata saved to the output\n",
      " \n",
      "  Example:\n",
      "      train_tissue_classifier /tables/slides/slide_table\n",
      "          -ne 5\n",
      "          -nt torchvision.models.resnet18\n",
      "          -nw 1\n",
      "          -o results/train_tile_classifier_results\n",
      "\n",
      "Options:\n",
      "  -o, --output_dir TEXT           Path to output directory to save results and\n",
      "                                  logs from Ray\n",
      "  -ls, --label_set TEXT           Dictionary/json where keys coorespoond to\n",
      "                                  tissue types and values coorespond to\n",
      "                                  numerical values\n",
      "  -lc, --label_col TEXT           Column name in the input dataframe\n",
      "                                  cooresponding to the tissue type (eg.\n",
      "                                  regional_label)\n",
      "  -sc, --stratify_col TEXT        Column name in the input dataframe used to\n",
      "                                  stratify the training/validation datasets\n",
      "                                  (eg. id_slide_container or patient_id)\n",
      "  -nk, --num_splits TEXT          The number of folds used for cross\n",
      "                                  validation\n",
      "  -ne, --num_epochs TEXT          Number of epochs to train the model for. Can\n",
      "                                  be either a fixed integer or a RayTune grid\n",
      "                                  search\n",
      "  -bx, --batch_size TEXT          Batch size used train the model. Can be\n",
      "                                  either a fixed integer or a RayTune grid\n",
      "                                  search\n",
      "  -lr, --learning_rate TEXT       Learning rate used for the ADAM optimizer.\n",
      "                                  Can be either a float or a RayTune\n",
      "                                  distribution\n",
      "  -nt, --network TEXT             Neural network architecture. Can be either a\n",
      "                                  nn.Module or a RayTune grid search\n",
      "  -ug, --use_gpu TEXT             Whether or not use use GPUs for model\n",
      "                                  training\n",
      "  -cw, --num_cpus_per_worker TEXT\n",
      "                                  Number of CPUs transparent to each worker\n",
      "  -gw, --num_gpus_per_worker TEXT\n",
      "                                  Number of GPUs transparent to each worker.\n",
      "                                  Can't be more than num_gpus\n",
      "  -ng, --num_gpus TEXT            Number of GPUs in total transparent to Ray\n",
      "  -nc, --num_cpus TEXT            Number of CPUs in total transparent to Ray\n",
      "  -nw, --num_workers TEXT         Total number of workers. Cooresponds to\n",
      "                                  number of models to train concurrently.\n",
      "  -ns, --num_samples TEXT         number of trials to run\n",
      "  -m, --method_param_path TEXT    path to a metadata json/yaml file with\n",
      "                                  method parameters to reproduce results\n",
      "  --help                          Show this message and exit.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!train_tissue_classifier --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40275193",
   "metadata": {},
   "source": [
    "This CLI tool has a lot of command line arguments. The main input is the labled tile dataset, which is the data used to train and valdiate the model. For validation, the tiles are stratified by patient id and by slide id, and the split is contoleled by the `num_splits` parameter. The `label_set` parameter is used to map the tissue types to numerical quantities. These models can use none, one, or many GPUs/CPUs using Ray. The arguments used to modify the resources are `num_gpus, num_cpus, num_workers, num_cpus_per_worker, num_gpus_per_worker`. If you want to experiment with different hyperparameters, you can supply a list of values to certian arguments, such as `learning_rate` or `batch_size` and Ray will perform a hyperparameter search or sweep accordingly. \n",
    "\n",
    "In the following example, we're going to train a ResNet18 model (though any model available from [PyTorch](https://pytorch.org/vision/stable/models.html) can be used) for two epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "7ef8144c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-10 13:49:19,165 - INFO - root - Initalized logger, log file at: data-processing.log\n",
      "2022-05-10 13:49:19,167 - INFO - luna.common.utils - Started CLI Runner wtih <function train_model at 0x7f6133a7b550>\n",
      "2022-05-10 13:49:19,168 - INFO - luna.common.utils - Validating params...\n",
      "2022-05-10 13:49:19,169 - INFO - luna.common.utils -  -> Set tile_dataset_fpath (<class 'str'>) = /home/kohlia/vmount/PRO_12-123/datasets/PRO_TILES_LABLED/\n",
      "2022-05-10 13:49:19,170 - INFO - luna.common.utils -  -> Set output_dir (<class 'str'>) = ../PRO_12-123/data/toy_data_set/table/tissue_classifier_results\n",
      "2022-05-10 13:49:19,171 - INFO - luna.common.utils -  -> Set label_set (<class 'dict'>) = {'tumor': 0, 'stroma': 1, 'fat': 2}\n",
      "2022-05-10 13:49:19,173 - INFO - luna.common.utils -  -> Set label_col (<class 'str'>) = regional_label\n",
      "2022-05-10 13:49:19,176 - INFO - luna.common.utils -  -> Set stratify_col (<class 'str'>) = slide_id\n",
      "2022-05-10 13:49:19,177 - INFO - luna.common.utils -  -> Set num_splits (<class 'int'>) = 2\n",
      "2022-05-10 13:49:19,178 - INFO - luna.common.utils -  -> Set num_epochs (typing.List[int]) = [2]\n",
      "2022-05-10 13:49:19,179 - INFO - luna.common.utils -  -> Set batch_size (typing.List[int]) = [4]\n",
      "2022-05-10 13:49:19,181 - INFO - luna.common.utils -  -> Set learning_rate (typing.List[float]) = [0.0001]\n",
      "2022-05-10 13:49:19,182 - INFO - luna.common.utils -  -> Set network (<class 'str'>) = torchvision.models.resnet18\n",
      "2022-05-10 13:49:19,183 - INFO - luna.common.utils -  -> Set num_cpus_per_worker (<class 'int'>) = 1\n",
      "2022-05-10 13:49:19,184 - INFO - luna.common.utils -  -> Set num_gpus_per_worker (<class 'int'>) = 0\n",
      "2022-05-10 13:49:19,185 - INFO - luna.common.utils -  -> Set num_gpus (<class 'int'>) = 0\n",
      "2022-05-10 13:49:19,186 - INFO - luna.common.utils -  -> Set num_cpus (<class 'int'>) = 4\n",
      "2022-05-10 13:49:19,187 - INFO - luna.common.utils -  -> Set num_workers (<class 'int'>) = 2\n",
      "2022-05-10 13:49:19,188 - INFO - luna.common.utils -  -> Set num_samples (<class 'int'>) = 1\n",
      "2022-05-10 13:49:19,190 - INFO - luna.common.utils - Expanding inputs...\n",
      "2022-05-10 13:49:19,191 - INFO - luna.common.utils - Full segment key set: {}\n",
      "2022-05-10 13:49:19,192 - INFO - luna.common.utils - ------------------------------------------------------------\n",
      "2022-05-10 13:49:19,192 - INFO - luna.common.utils -  Starting transform::train_model \n",
      "2022-05-10 13:49:19,192 - INFO - luna.common.utils - ------------------------------------------------------------\n",
      "2022-05-10 13:49:19,194 - INFO - train_tissue_classifier - Training a tissue classifier with: network=torchvision.models.resnet18, batch_size=[4], learning_rate=[0.0001]\n",
      "2022-05-10 13:49:19,195 - INFO - train_tissue_classifier - Initilizing Ray Cluster, with: num_gpus=0, num_workers=2\n",
      "2022-05-10 13:49:20,260\tWARNING services.py:1909 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67076096 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=1.19gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "2022-05-10 13:49:22,253 - INFO - train_tissue_classifier - View Ray Dashboard to see worker logs: None\n",
      "2022-05-10 13:49:22,255 - INFO - train_tissue_classifier - Instantiating Ray Trainer with: num_cpus_per_worker=1, num_gpus_per_worker=0\n",
      "2022-05-10 13:49:22,258\tINFO trainer.py:199 -- Trainer logs will be logged in: /home/kohlia/PRO_12-123/data/toy_data_set/table/tissue_classifier_results\n",
      "2022-05-10 13:49:22,285 - INFO - train_tissue_classifier - Trainer logs will be logged in: ../PRO_12-123/data/toy_data_set/table/tissue_classifier_results\n",
      "2022-05-10 13:49:23,225\tERROR syncer.py:111 -- Log sync requires rsync to be installed.\n",
      "2022-05-10 13:49:25,724 - INFO - train_tissue_classifier - == Status ==\n",
      "2022-05-10 13:49:25,724 - INFO - train_tissue_classifier - Current time: 2022-05-10 13:49:25 (running for 00:00:02.65)\n",
      "2022-05-10 13:49:25,724 - INFO - train_tissue_classifier - Memory usage on this node: 5.0/7.7 GiB\n",
      "2022-05-10 13:49:25,724 - INFO - train_tissue_classifier - Using FIFO scheduling algorithm.\n",
      "2022-05-10 13:49:25,724 - INFO - train_tissue_classifier - Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/2.17 GiB heap, 0.0/1.08 GiB objects\n",
      "2022-05-10 13:49:25,724 - INFO - train_tissue_classifier - Result logdir: /home/kohlia/vmount/PRO_12-123/data/toy_data_set/table/tissue_classifier_results/tune_function_2022-05-10_13-49-23\n",
      "2022-05-10 13:49:25,724 - INFO - train_tissue_classifier - Number of trials: 1/1 (1 RUNNING)\n",
      "2022-05-10 13:49:25,724 - INFO - train_tissue_classifier - +---------------------------+----------+------------------+--------------+-----------------+--------------+\n",
      "2022-05-10 13:49:25,724 - INFO - train_tissue_classifier - | Trial name                | status   | loc              |   batch_size |   learning_rate |   num_epochs |\n",
      "2022-05-10 13:49:25,724 - INFO - train_tissue_classifier - |---------------------------+----------+------------------+--------------+-----------------+--------------|\n",
      "2022-05-10 13:49:25,724 - INFO - train_tissue_classifier - | tune_function_ff99e_00000 | RUNNING  | 172.20.0.3:79237 |            4 |          0.0001 |            2 |\n",
      "2022-05-10 13:49:25,724 - INFO - train_tissue_classifier - +---------------------------+----------+------------------+--------------+-----------------+--------------+\n",
      "2022-05-10 13:49:25,724 - INFO - train_tissue_classifier -\n",
      "\u001b[2m\u001b[36m(bundle_reservation_check_func pid=79237)\u001b[0m 2022-05-10 13:49:25,713 - INFO - root - Initalized logger, log file at: data-processing.log\n",
      "\u001b[2m\u001b[36m(TrainTrainable pid=79237)\u001b[0m 2022-05-10 13:49:25,836\tINFO trainer.py:199 -- Trainer logs will be logged in: /home/kohlia/ray_results/train_2022-05-10_13-49-25\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=79234)\u001b[0m 2022-05-10 13:49:28,592\tINFO torch.py:66 -- Setting up process group for: env:// [rank=0, world_size=2]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=79414)\u001b[0m 2022-05-10 13:49:28,590\tINFO torch.py:66 -- Setting up process group for: env:// [rank=1, world_size=2]\n",
      "\u001b[2m\u001b[36m(TrainTrainable pid=79237)\u001b[0m 2022-05-10 13:49:29,626\tINFO trainer.py:205 -- Run results will be logged in: /home/kohlia/ray_results/train_2022-05-10_13-49-25/run_001\n",
      "\u001b[2m\u001b[36m(BackendExecutor pid=79235)\u001b[0m 2022-05-10 13:49:31,428 - INFO - root - Initalized logger, log file at: data-processing.log\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=79234)\u001b[0m 2022-05-10 13:49:33,341 - INFO - root - Initalized logger, log file at: data-processing.log\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=79234)\u001b[0m 2022-05-10 13:49:33,345 - INFO - train_tissue_classifier - Configuring model training driver function...\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=79414)\u001b[0m 2022-05-10 13:49:33,336 - INFO - root - Initalized logger, log file at: data-processing.log\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=79414)\u001b[0m 2022-05-10 13:49:33,345 - INFO - train_tissue_classifier - Configuring model training driver function...\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=79234)\u001b[0m 2022-05-10 13:49:33,623\tINFO torch.py:244 -- Moving model to device: cpu\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=79234)\u001b[0m 2022-05-10 13:49:33,623\tINFO torch.py:247 -- Wrapping provided model in DDP.\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=79414)\u001b[0m 2022-05-10 13:49:33,619\tINFO torch.py:244 -- Moving model to device: cpu\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=79414)\u001b[0m 2022-05-10 13:49:33,620\tINFO torch.py:247 -- Wrapping provided model in DDP.\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=79234)\u001b[0m 2022-05-10 13:49:33,682 - INFO - train_tissue_classifier - Starting training procedure\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=79414)\u001b[0m 2022-05-10 13:49:33,682 - INFO - train_tissue_classifier - Starting training procedure\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=79234)\u001b[0m 2022-05-10 13:49:34,259 - INFO - root - Reducer buckets have been rebuilt in this iteration.\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=79414)\u001b[0m 2022-05-10 13:49:34,259 - INFO - root - Reducer buckets have been rebuilt in this iteration.\n",
      "2022-05-10 13:52:23,988 - INFO - train_tissue_classifier - == Status ==\n",
      "2022-05-10 13:52:23,988 - INFO - train_tissue_classifier - Current time: 2022-05-10 13:52:23 (running for 00:03:00.92)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-10 13:52:23,988 - INFO - train_tissue_classifier - Memory usage on this node: 6.3/7.7 GiB\n",
      "2022-05-10 13:52:23,988 - INFO - train_tissue_classifier - Using FIFO scheduling algorithm.\n",
      "2022-05-10 13:52:23,988 - INFO - train_tissue_classifier - Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/2.17 GiB heap, 0.0/1.08 GiB objects\n",
      "2022-05-10 13:52:23,988 - INFO - train_tissue_classifier - Result logdir: /home/kohlia/vmount/PRO_12-123/data/toy_data_set/table/tissue_classifier_results/tune_function_2022-05-10_13-49-23\n",
      "2022-05-10 13:52:23,988 - INFO - train_tissue_classifier - Number of trials: 1/1 (1 RUNNING)\n",
      "2022-05-10 13:52:23,988 - INFO - train_tissue_classifier - +---------------------------+----------+------------------+--------------+-----------------+--------------+\n",
      "2022-05-10 13:52:23,988 - INFO - train_tissue_classifier - | Trial name                | status   | loc              |   batch_size |   learning_rate |   num_epochs |\n",
      "2022-05-10 13:52:23,988 - INFO - train_tissue_classifier - |---------------------------+----------+------------------+--------------+-----------------+--------------|\n",
      "2022-05-10 13:52:23,988 - INFO - train_tissue_classifier - | tune_function_ff99e_00000 | RUNNING  | 172.20.0.3:79237 |            4 |          0.0001 |            2 |\n",
      "2022-05-10 13:52:23,988 - INFO - train_tissue_classifier - +---------------------------+----------+------------------+--------------+-----------------+--------------+\n",
      "2022-05-10 13:52:23,988 - INFO - train_tissue_classifier -\n",
      "2022-05-10 13:55:24,712 - INFO - train_tissue_classifier - == Status ==\n",
      "2022-05-10 13:55:24,712 - INFO - train_tissue_classifier - Current time: 2022-05-10 13:55:24 (running for 00:06:01.64)\n",
      "2022-05-10 13:55:24,712 - INFO - train_tissue_classifier - Memory usage on this node: 7.0/7.7 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "2022-05-10 13:55:24,712 - INFO - train_tissue_classifier - Using FIFO scheduling algorithm.\n",
      "2022-05-10 13:55:24,712 - INFO - train_tissue_classifier - Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/2.17 GiB heap, 0.0/1.08 GiB objects\n",
      "2022-05-10 13:55:24,712 - INFO - train_tissue_classifier - Current best trial: ff99e_00000 with val_Accuracy=0.8153364658355713 and parameters={'learning_rate': 0.0001, 'batch_size': 4, 'num_epochs': 2, 'num_cpus_per_worker': 1, 'tile_dataset_fpath': '/home/kohlia/vmount/PRO_12-123/datasets/PRO_TILES_LABLED/', 'label_set': {'tumor': 0, 'stroma': 1, 'fat': 2}, 'label_col': 'regional_label', 'stratify_col': 'slide_id', 'network': <function resnet18 at 0x7f615d1369d0>, 'num_splits': 2}\n",
      "2022-05-10 13:55:24,712 - INFO - train_tissue_classifier - Result logdir: /home/kohlia/vmount/PRO_12-123/data/toy_data_set/table/tissue_classifier_results/tune_function_2022-05-10_13-49-23\n",
      "2022-05-10 13:55:24,712 - INFO - train_tissue_classifier - Number of trials: 1/1 (1 RUNNING)\n",
      "2022-05-10 13:55:24,712 - INFO - train_tissue_classifier - +---------------------------+----------+------------------+--------------+-----------------+--------------+--------+------------------+--------------+------------+--------------+\n",
      "2022-05-10 13:55:24,712 - INFO - train_tissue_classifier - | Trial name                | status   | loc              |   batch_size |   learning_rate |   num_epochs |   iter |   total time (s) |   train_loss |   val_loss |   _timestamp |\n",
      "2022-05-10 13:55:24,712 - INFO - train_tissue_classifier - |---------------------------+----------+------------------+--------------+-----------------+--------------+--------+------------------+--------------+------------+--------------|\n",
      "2022-05-10 13:55:24,712 - INFO - train_tissue_classifier - | tune_function_ff99e_00000 | RUNNING  | 172.20.0.3:79237 |            4 |          0.0001 |            2 |      1 |           339.93 |     0.483523 |   0.480489 |   1652190905 |\n",
      "2022-05-10 13:55:24,712 - INFO - train_tissue_classifier - +---------------------------+----------+------------------+--------------+-----------------+--------------+--------+------------------+--------------+------------+--------------+\n",
      "2022-05-10 13:55:24,712 - INFO - train_tissue_classifier -\n",
      "2022-05-10 13:58:25,024 - INFO - train_tissue_classifier - == Status ==\n",
      "2022-05-10 13:58:25,024 - INFO - train_tissue_classifier - Current time: 2022-05-10 13:58:25 (running for 00:09:01.95)\n",
      "2022-05-10 13:58:25,024 - INFO - train_tissue_classifier - Memory usage on this node: 6.9/7.7 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "2022-05-10 13:58:25,024 - INFO - train_tissue_classifier - Using FIFO scheduling algorithm.\n",
      "2022-05-10 13:58:25,024 - INFO - train_tissue_classifier - Resources requested: 3.0/4 CPUs, 0/0 GPUs, 0.0/2.17 GiB heap, 0.0/1.08 GiB objects\n",
      "2022-05-10 13:58:25,024 - INFO - train_tissue_classifier - Current best trial: ff99e_00000 with val_Accuracy=0.8153364658355713 and parameters={'learning_rate': 0.0001, 'batch_size': 4, 'num_epochs': 2, 'num_cpus_per_worker': 1, 'tile_dataset_fpath': '/home/kohlia/vmount/PRO_12-123/datasets/PRO_TILES_LABLED/', 'label_set': {'tumor': 0, 'stroma': 1, 'fat': 2}, 'label_col': 'regional_label', 'stratify_col': 'slide_id', 'network': <function resnet18 at 0x7f615d1369d0>, 'num_splits': 2}\n",
      "2022-05-10 13:58:25,024 - INFO - train_tissue_classifier - Result logdir: /home/kohlia/vmount/PRO_12-123/data/toy_data_set/table/tissue_classifier_results/tune_function_2022-05-10_13-49-23\n",
      "2022-05-10 13:58:25,024 - INFO - train_tissue_classifier - Number of trials: 1/1 (1 RUNNING)\n",
      "2022-05-10 13:58:25,024 - INFO - train_tissue_classifier - +---------------------------+----------+------------------+--------------+-----------------+--------------+--------+------------------+--------------+------------+--------------+\n",
      "2022-05-10 13:58:25,024 - INFO - train_tissue_classifier - | Trial name                | status   | loc              |   batch_size |   learning_rate |   num_epochs |   iter |   total time (s) |   train_loss |   val_loss |   _timestamp |\n",
      "2022-05-10 13:58:25,024 - INFO - train_tissue_classifier - |---------------------------+----------+------------------+--------------+-----------------+--------------+--------+------------------+--------------+------------+--------------|\n",
      "2022-05-10 13:58:25,024 - INFO - train_tissue_classifier - | tune_function_ff99e_00000 | RUNNING  | 172.20.0.3:79237 |            4 |          0.0001 |            2 |      1 |           339.93 |     0.483523 |   0.480489 |   1652190905 |\n",
      "2022-05-10 13:58:25,024 - INFO - train_tissue_classifier - +---------------------------+----------+------------------+--------------+-----------------+--------------+--------+------------------+--------------+------------+--------------+\n",
      "2022-05-10 13:58:25,024 - INFO - train_tissue_classifier -\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=79414)\u001b[0m 2022-05-10 14:00:48,515 - INFO - train_tissue_classifier - Completed model training\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=79234)\u001b[0m 2022-05-10 14:00:48,553 - INFO - train_tissue_classifier - Completed model training\n",
      "2022-05-10 14:00:49,324 - INFO - train_tissue_classifier - == Status ==\n",
      "2022-05-10 14:00:49,324 - INFO - train_tissue_classifier - Current time: 2022-05-10 14:00:49 (running for 00:11:26.25)\n",
      "2022-05-10 14:00:49,324 - INFO - train_tissue_classifier - Memory usage on this node: 5.8/7.7 GiB\n",
      "2022-05-10 14:00:49,324 - INFO - train_tissue_classifier - Using FIFO scheduling algorithm.\n",
      "2022-05-10 14:00:49,324 - INFO - train_tissue_classifier - Resources requested: 0/4 CPUs, 0/0 GPUs, 0.0/2.17 GiB heap, 0.0/1.08 GiB objects\n",
      "2022-05-10 14:00:49,324 - INFO - train_tissue_classifier - Current best trial: ff99e_00000 with val_Accuracy=0.8916275501251221 and parameters={'learning_rate': 0.0001, 'batch_size': 4, 'num_epochs': 2, 'num_cpus_per_worker': 1, 'tile_dataset_fpath': '/home/kohlia/vmount/PRO_12-123/datasets/PRO_TILES_LABLED/', 'label_set': {'tumor': 0, 'stroma': 1, 'fat': 2}, 'label_col': 'regional_label', 'stratify_col': 'slide_id', 'network': <function resnet18 at 0x7f615d1369d0>, 'num_splits': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-10 14:00:49,324 - INFO - train_tissue_classifier - Result logdir: /home/kohlia/vmount/PRO_12-123/data/toy_data_set/table/tissue_classifier_results/tune_function_2022-05-10_13-49-23\n",
      "2022-05-10 14:00:49,324 - INFO - train_tissue_classifier - Number of trials: 1/1 (1 TERMINATED)\n",
      "2022-05-10 14:00:49,324 - INFO - train_tissue_classifier - +---------------------------+------------+------------------+--------------+-----------------+--------------+--------+------------------+--------------+------------+--------------+\n",
      "2022-05-10 14:00:49,324 - INFO - train_tissue_classifier - | Trial name                | status     | loc              |   batch_size |   learning_rate |   num_epochs |   iter |   total time (s) |   train_loss |   val_loss |   _timestamp |\n",
      "2022-05-10 14:00:49,324 - INFO - train_tissue_classifier - |---------------------------+------------+------------------+--------------+-----------------+--------------+--------+------------------+--------------+------------+--------------|\n",
      "2022-05-10 14:00:49,324 - INFO - train_tissue_classifier - | tune_function_ff99e_00000 | TERMINATED | 172.20.0.3:79237 |            4 |          0.0001 |            2 |      2 |          682.754 |      0.20686 |  0.0844222 |   1652191248 |\n",
      "2022-05-10 14:00:49,324 - INFO - train_tissue_classifier - +---------------------------+------------+------------------+--------------+-----------------+--------------+--------+------------------+--------------+------------+--------------+\n",
      "2022-05-10 14:00:49,324 - INFO - train_tissue_classifier -\n",
      "2022-05-10 14:00:49,431\tINFO tune.py:639 -- Total run time: 686.42 seconds (686.24 seconds for the tuning loop).\n",
      "2022-05-10 14:00:49,445 - INFO - train_tissue_classifier - Finished training\n",
      "/home/kohlia/.local/lib/python3.9/site-packages/ray/tune/analysis/experiment_analysis.py:281: UserWarning: Dataframes will use '/' instead of '.' to delimit nested result keys in future versions of Ray. For forward compatibility, set the environment variable TUNE_RESULT_DELIM='/'\n",
      "  warnings.warn(\n",
      "2022-05-10 14:00:49,495 - INFO - train_tissue_classifier -             train_Accuracy  ... config.label_set.fat\n",
      "2022-05-10 14:00:49,495 - INFO - train_tissue_classifier - trial_id                    ...                     \n",
      "2022-05-10 14:00:49,495 - INFO - train_tissue_classifier - ff99e_00000      0.8794014  ...                    2\n",
      "2022-05-10 14:00:49,495 - INFO - train_tissue_classifier - \n",
      "2022-05-10 14:00:49,495 - INFO - train_tissue_classifier - [1 rows x 43 columns]\n",
      "2022-05-10 14:00:49,506 - INFO - train_tissue_classifier - Output: ../PRO_12-123/data/toy_data_set/table/tissue_classifier_results\n",
      "2022-05-10 14:00:51,852 - INFO - luna.common.utils - Code block 'transform::train_model' took: 693.1433984108735s\n",
      "2022-05-10 14:00:51,854 - INFO - luna.common.utils - ------------------------------------------------------------\n",
      "2022-05-10 14:00:51,854 - INFO - luna.common.utils -  Done with transform, running post-transform functions... \n",
      "2022-05-10 14:00:51,854 - INFO - luna.common.utils - ------------------------------------------------------------\n",
      "2022-05-10 14:00:51,872 - INFO - luna.common.utils - Done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model\n",
      "Result for tune_function_ff99e_00000:\n",
      "  _time_this_iter_s: 332.3070001602173\n",
      "  _timestamp: 1652190905\n",
      "  _training_iteration: 1\n",
      "  date: 2022-05-10_13-55-05\n",
      "  done: false\n",
      "  experiment_id: eaa2ec00cb6546179220889ed6c1ec28\n",
      "  hostname: a6f0744d4bbb\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 172.20.0.3\n",
      "  pid: 79237\n",
      "  time_since_restore: 339.93007469177246\n",
      "  time_this_iter_s: 339.93007469177246\n",
      "  time_total_s: 339.93007469177246\n",
      "  timestamp: 1652190905\n",
      "  timesteps_since_restore: 0\n",
      "  train_Accuracy: 0.8253129720687866\n",
      "  train_F1Score: 0.8253129720687866\n",
      "  train_Precision: 0.8253129720687866\n",
      "  train_Recall: 0.8253129720687866\n",
      "  train_loss: 0.4835228884333223\n",
      "  training_iteration: 1\n",
      "  trial_id: ff99e_00000\n",
      "  val_Accuracy: 0.8153364658355713\n",
      "  val_ConfusionMatrix:\n",
      "  - - 2498\n",
      "    - 452\n",
      "    - 2\n",
      "  - - 16\n",
      "    - 1408\n",
      "    - 0\n",
      "  - - 16\n",
      "    - 458\n",
      "    - 262\n",
      "  val_F1Score: 0.8153364062309265\n",
      "  val_Precision: 0.8153364658355713\n",
      "  val_Recall: 0.8153364658355713\n",
      "  val_loss: 0.4804891074733613\n",
      "  \n",
      "Result for tune_function_ff99e_00000:\n",
      "  _time_this_iter_s: 342.8142273426056\n",
      "  _timestamp: 1652191248\n",
      "  _training_iteration: 2\n",
      "  date: 2022-05-10_14-00-48\n",
      "  done: false\n",
      "  experiment_id: eaa2ec00cb6546179220889ed6c1ec28\n",
      "  hostname: a6f0744d4bbb\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 172.20.0.3\n",
      "  pid: 79237\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 682.7541711330414\n",
      "  time_this_iter_s: 342.8240964412689\n",
      "  time_total_s: 682.7541711330414\n",
      "  timestamp: 1652191248\n",
      "  timesteps_since_restore: 0\n",
      "  train_Accuracy: 0.8794013857841492\n",
      "  train_F1Score: 0.8794013857841492\n",
      "  train_Precision: 0.8794013857841492\n",
      "  train_Recall: 0.8794013857841492\n",
      "  train_loss: 0.2068598057662249\n",
      "  training_iteration: 2\n",
      "  trial_id: ff99e_00000\n",
      "  val_Accuracy: 0.8916275501251221\n",
      "  val_ConfusionMatrix:\n",
      "  - - 5428\n",
      "    - 456\n",
      "    - 20\n",
      "  - - 78\n",
      "    - 2724\n",
      "    - 46\n",
      "  - - 30\n",
      "    - 478\n",
      "    - 964\n",
      "  val_F1Score: 0.8916274905204773\n",
      "  val_Precision: 0.8916275501251221\n",
      "  val_Recall: 0.8916275501251221\n",
      "  val_loss: 0.08442224559721168\n",
      "  \n",
      "Result for tune_function_ff99e_00000:\n",
      "  _time_this_iter_s: 342.8142273426056\n",
      "  _timestamp: 1652191248\n",
      "  _training_iteration: 2\n",
      "  date: 2022-05-10_14-00-48\n",
      "  done: true\n",
      "  experiment_id: eaa2ec00cb6546179220889ed6c1ec28\n",
      "  experiment_tag: 0_batch_size=4,learning_rate=0.0001,num_epochs=2\n",
      "  hostname: a6f0744d4bbb\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 172.20.0.3\n",
      "  pid: 79237\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 682.7541711330414\n",
      "  time_this_iter_s: 342.8240964412689\n",
      "  time_total_s: 682.7541711330414\n",
      "  timestamp: 1652191248\n",
      "  timesteps_since_restore: 0\n",
      "  train_Accuracy: 0.8794013857841492\n",
      "  train_F1Score: 0.8794013857841492\n",
      "  train_Precision: 0.8794013857841492\n",
      "  train_Recall: 0.8794013857841492\n",
      "  train_loss: 0.2068598057662249\n",
      "  training_iteration: 2\n",
      "  trial_id: ff99e_00000\n",
      "  val_Accuracy: 0.8916275501251221\n",
      "  val_ConfusionMatrix:\n",
      "  - - 5428\n",
      "    - 456\n",
      "    - 20\n",
      "  - - 78\n",
      "    - 2724\n",
      "    - 46\n",
      "  - - 30\n",
      "    - 478\n",
      "    - 964\n",
      "  val_F1Score: 0.8916274905204773\n",
      "  val_Precision: 0.8916275501251221\n",
      "  val_Recall: 0.8916275501251221\n",
      "  val_loss: 0.08442224559721168\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "train_tissue_classifier ~/vmount/PRO_12-123/datasets/PRO_TILES_LABLED/ \\\n",
    "--label_set \"{'tumor':0, 'stroma':1, 'fat':2}\" \\\n",
    "--label_col regional_label --stratify_col slide_id \\\n",
    "--num_epochs 2 --network 'torchvision.models.resnet18' \\\n",
    "--num_splits 2 \\\n",
    "--batch_size 4 \\\n",
    "-lr 1e-4  \\\n",
    "-cw 1 -gw 0 -nw 2 -ng 0 -nc 4 -ns 1 \\\n",
    "--output_dir ../PRO_12-123/data/toy_data_set/table/tissue_classifier_results \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b59013",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "Now that we have a trained model, we can inspect the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "002585c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata.yml\t\t\t   tune_function_2022-05-10_13-49-10\r\n",
      "tune_function_2022-05-10_05-04-22  tune_function_2022-05-10_13-49-23\r\n",
      "tune_function_2022-05-10_13-40-42\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../PRO_12-123/data/toy_data_set/table/tissue_classifier_results/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d16db1f",
   "metadata": {},
   "source": [
    "For every time the model is trained, Ray will put together a set of output directories to manage your runs. You can inspect the results using Ray's ExperimentAnalysis dataframe by loading a particular output directory. This dataframe will store various performance metrics as well as the hyperparameters used to configure the model among other output metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "75de5070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_Accuracy</th>\n",
       "      <th>train_Precision</th>\n",
       "      <th>train_Recall</th>\n",
       "      <th>train_F1Score</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_Accuracy</th>\n",
       "      <th>val_Precision</th>\n",
       "      <th>val_Recall</th>\n",
       "      <th>val_F1Score</th>\n",
       "      <th>val_ConfusionMatrix</th>\n",
       "      <th>...</th>\n",
       "      <th>config.num_epochs</th>\n",
       "      <th>config.num_cpus_per_worker</th>\n",
       "      <th>config.tile_dataset_fpath</th>\n",
       "      <th>config.label_col</th>\n",
       "      <th>config.stratify_col</th>\n",
       "      <th>config.network</th>\n",
       "      <th>config.num_splits</th>\n",
       "      <th>config.label_set.tumor</th>\n",
       "      <th>config.label_set.stroma</th>\n",
       "      <th>config.label_set.fat</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trial_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ff99e_00000</th>\n",
       "      <td>0.8794014</td>\n",
       "      <td>0.8794014</td>\n",
       "      <td>0.8794014</td>\n",
       "      <td>0.8794014</td>\n",
       "      <td>0.20686</td>\n",
       "      <td>0.89162755</td>\n",
       "      <td>0.89162755</td>\n",
       "      <td>0.89162755</td>\n",
       "      <td>0.8916275</td>\n",
       "      <td>[[5428, 456, 20], [78, 2724, 46], [30, 478, 964]]</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>/home/kohlia/vmount/PRO_12-123/datasets/PRO_TI...</td>\n",
       "      <td>regional_label</td>\n",
       "      <td>slide_id</td>\n",
       "      <td>&lt;function resnet18 at 0x7fa4ebe6cd30&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            train_Accuracy train_Precision train_Recall train_F1Score  \\\n",
       "trial_id                                                                \n",
       "ff99e_00000      0.8794014       0.8794014    0.8794014     0.8794014   \n",
       "\n",
       "             train_loss val_Accuracy val_Precision  val_Recall val_F1Score  \\\n",
       "trial_id                                                                     \n",
       "ff99e_00000     0.20686   0.89162755    0.89162755  0.89162755   0.8916275   \n",
       "\n",
       "                                           val_ConfusionMatrix  ...  \\\n",
       "trial_id                                                        ...   \n",
       "ff99e_00000  [[5428, 456, 20], [78, 2724, 46], [30, 478, 964]]  ...   \n",
       "\n",
       "             config.num_epochs  config.num_cpus_per_worker  \\\n",
       "trial_id                                                     \n",
       "ff99e_00000                  2                           1   \n",
       "\n",
       "                                     config.tile_dataset_fpath  \\\n",
       "trial_id                                                         \n",
       "ff99e_00000  /home/kohlia/vmount/PRO_12-123/datasets/PRO_TI...   \n",
       "\n",
       "             config.label_col  config.stratify_col  \\\n",
       "trial_id                                             \n",
       "ff99e_00000    regional_label             slide_id   \n",
       "\n",
       "                                    config.network  config.num_splits  \\\n",
       "trial_id                                                                \n",
       "ff99e_00000  <function resnet18 at 0x7fa4ebe6cd30>                  2   \n",
       "\n",
       "            config.label_set.tumor config.label_set.stroma  \\\n",
       "trial_id                                                     \n",
       "ff99e_00000                      0                       1   \n",
       "\n",
       "             config.label_set.fat  \n",
       "trial_id                           \n",
       "ff99e_00000                     2  \n",
       "\n",
       "[1 rows x 43 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ray.tune import ExperimentAnalysis\n",
    "RAY_OUTPUT = \"tune_function_2022-05-10_13-49-23\" # change this to the output folder you want to insepct\n",
    "output_dir = \"../PRO_12-123/data/toy_data_set/table/tissue_classifier_results\"\n",
    "\n",
    "ray_output_dir = os.path.join(output_dir, RAY_OUTPUT)\n",
    "analysis = ExperimentAnalysis(ray_output_dir)\n",
    "display(analysis.results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256b85a0",
   "metadata": {},
   "source": [
    "We can use the output to put together a confusion matrix. The calssifier can pretty successfully distinguish tumor tissue from the other classes, but it seems like fat is often mis-classified as stroma. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "6e5366d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "label_dict = {'tumor':0, 'stroma':1, 'fat':2}\n",
    "labels = list(label_dict.keys())\n",
    "cm = analysis.results_df['val_ConfusionMatrix'].iloc[0]\n",
    "# normalize \n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "df_cm = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "df_cm\n",
    "sns.heatmap(df_cm, annot=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93bd09c",
   "metadata": {},
   "source": [
    "The ray output directory also contains a tensorboard file (`events.out.tf.events.*`) in the `'tune_function_*'` subdirectory that can be used to further evaluate the performance of the model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "1584d736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m../PRO_12-123/data/toy_data_set/table/tissue_classifier_results/tune_function_2022-05-10_13-49-23\u001b[00m\r\n",
      "â”œâ”€â”€ basic-variant-state-2022-05-10_13-49-23.json\r\n",
      "â”œâ”€â”€ experiment_state-2022-05-10_13-49-23.json\r\n",
      "â””â”€â”€ \u001b[01;34mtune_function_ff99e_00000_0_batch_size=4,learning_rate=0.0001,num_epochs=2_2022-05-10_13-49-23\u001b[00m\r\n",
      "    â”œâ”€â”€ \u001b[01;34mcheckpoint_000000\u001b[00m\r\n",
      "    â”‚Â Â  â””â”€â”€ checkpoint\r\n",
      "    â”œâ”€â”€ \u001b[01;34mcheckpoint_000001\u001b[00m\r\n",
      "    â”‚Â Â  â””â”€â”€ checkpoint\r\n",
      "    â”œâ”€â”€ events.out.tfevents.1652190563.a6f0744d4bbb\r\n",
      "    â”œâ”€â”€ params.json\r\n",
      "    â”œâ”€â”€ params.pkl\r\n",
      "    â”œâ”€â”€ progress.csv\r\n",
      "    â”œâ”€â”€ result.json\r\n",
      "    â”œâ”€â”€ stderr\r\n",
      "    â””â”€â”€ stdout\r\n",
      "\r\n",
      "3 directories, 11 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree $ray_output_dir\n",
    "# %load_ext tensorboard\n",
    "# ! tensorboard --logdir os.path.join(ray_output_dir,'tune_function_ff99e_00000_0_batch_size=4,learning_rate=0.0001,num_epochs=2_2022-05-10_13-49-23') --bind_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c999c1",
   "metadata": {},
   "source": [
    "This `'tune_function_*'` directory also contains our model checkpoints in the `check_point_*` directories that we'll need for inference. Now, with our trained model and model checkpoints, we can move on the next notebook!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
